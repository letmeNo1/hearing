import cv2
import numpy as np
import json
import tkinter as tk
from tkinter import ttk, messagebox
import os
import threading

# å…¨å±€å˜é‡
cap = None
cam_width = 1920
cam_height = 1080
cam_total_area = cam_width * cam_height
is_previewing = False
is_detecting = False
is_previewing_white = False

# æ˜¾ç¤ºç¼©æ”¾é…ç½®
DISPLAY_SCALE = 0.5
display_width = int(cam_width * DISPLAY_SCALE)
display_height = int(cam_height * DISPLAY_SCALE)

# ===================== ç½‘æ ¼é…ç½® =====================
HEARING_AID_GRID_ROWS = 4
HEARING_AID_GRID_COLS_CALC = 14
HEARING_AID_GRID_COLS_DISPLAY = 13
HEARING_AID_GRID_COLOR = (255, 0, 0)
HEARING_AID_GRID_THICKNESS = 2

WHITE_GRID_ROWS = 2
WHITE_GRID_COLS = 5
WHITE_BORDER_COLOR = (255, 255, 255)
WHITE_BORDER_THICKNESS = 5
WHITE_GRID_COLOR = (255, 0, 0)
WHITE_GRID_THICKNESS = 2

WHITE_BORDER_JSON_PATH = "charging_case_border.json"


# ===================== æ ¸å¿ƒå‡½æ•°ï¼šç§»é™¤ç•¸å˜é€»è¾‘ =====================

def init_camera():
    """åˆå§‹åŒ–æ‘„åƒå¤´ï¼Œå¼ºåˆ¶åŸå§‹ 1920x1080 å°ºå¯¸"""
    global cap
    cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        messagebox.showerror("é”™è¯¯", "âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼")
        return False
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
    return True


def draw_HEARING_AID_grid(frame, target_rect):
    """ç²‰è‰²æ¡†ç½‘æ ¼ï¼š14ç­‰åˆ†è®¡ç®—ï¼Œæ˜¾ç¤º13åˆ—ï¼Œ4è¡Œï¼Œä¿ç•™åç§»"""
    if target_rect is None: return frame
    frame_copy = frame.copy()
    x, y, w, h = target_rect
    grid_w = w / HEARING_AID_GRID_COLS_CALC
    grid_h = h / HEARING_AID_GRID_ROWS
    x_new = int(x + grid_w / 2)

    # ç»˜åˆ¶ç½‘æ ¼
    for col in range(HEARING_AID_GRID_COLS_DISPLAY + 1):
        curr_x = int(x_new + col * grid_w)
        cv2.line(frame_copy, (curr_x, y), (curr_x, y + h), HEARING_AID_GRID_COLOR, HEARING_AID_GRID_THICKNESS)
    for row in range(HEARING_AID_GRID_ROWS + 1):
        curr_y = int(y + row * grid_h)
        line_end = int(x_new + HEARING_AID_GRID_COLS_DISPLAY * grid_w)
        cv2.line(frame_copy, (x_new, curr_y), (line_end, curr_y), HEARING_AID_GRID_COLOR, HEARING_AID_GRID_THICKNESS)
    return frame_copy


def draw_white_grid(frame, target_rect):
    """ç™½è‰²æ¡†ç½‘æ ¼ï¼š5åˆ—2è¡Œï¼Œæ— åç§»"""
    if target_rect is None: return frame
    frame_copy = frame.copy()
    x, y, w, h = target_rect
    grid_w, grid_h = w / WHITE_GRID_COLS, h / WHITE_GRID_ROWS
    for i in range(WHITE_GRID_COLS + 1):
        cx = int(x + i * grid_w)
        cv2.line(frame_copy, (cx, y), (cx, y + h), WHITE_GRID_COLOR, WHITE_GRID_THICKNESS)
    for i in range(WHITE_GRID_ROWS + 1):
        cy = int(y + i * grid_h)
        cv2.line(frame_copy, (x, cy), (x + w, cy), WHITE_GRID_COLOR, WHITE_GRID_THICKNESS)
    return frame_copy


# ===================== æ£€æµ‹ä¸é¢„è§ˆé€»è¾‘ =====================

def detect_contours_by_ratio(target_ratio_range):
    global cap, is_detecting
    if not init_camera(): return
    is_detecting = True
    print("\nğŸ” å¼€å§‹æ£€æµ‹åŸå§‹ç”»é¢ï¼ˆæ— ç•¸å˜æ ¡æ­£ï¼‰")

    while is_detecting:
        ret, frame = cap.read()
        if not ret: continue

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (7, 7), 0)
        binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        frame_copy = frame.copy()
        target_rect = None
        current_detected = []

        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < 2000: continue
            x, y, w, h = cv2.boundingRect(cnt)
            rect_ratio = ((w * h) / cam_total_area) * 100

            if target_ratio_range[0] <= rect_ratio <= target_ratio_range[1]:
                box = np.int32(cv2.boxPoints(cv2.minAreaRect(cnt)))
                current_detected.append({
                    "rect_ratio": round(rect_ratio, 2),
                    "bounding_box_coordinates": box.tolist(),
                    "bounding_rect": (x, y, w, h)
                })
                cv2.drawContours(frame_copy, [box], 0, (0, 255, 0), 4)
                target_rect = (x, y, w, h)

        frame_final = draw_HEARING_AID_grid(frame_copy, target_rect)
        cv2.imshow("Detection - Original Frame", cv2.resize(frame_final, (display_width, display_height)))

        if (cv2.waitKey(1) & 0xFF == ord('q')) or current_detected:
            if current_detected:
                with open("hearing_aid_border.json", "w") as f:
                    json.dump({"contours": current_detected}, f, indent=4)
            break

    is_detecting = False
    cap.release()
    cv2.destroyAllWindows()


def preview_saved_contours(grid_type="hearing_aid"):
    global is_previewing, is_previewing_white, cap
    json_path = "hearing_aid_border.json" if grid_type == "hearing_aid" else WHITE_BORDER_JSON_PATH
    if not os.path.exists(json_path):
        messagebox.showerror("é”™è¯¯", f"æœªæ‰¾åˆ° {json_path}")
        return
    if not init_camera(): return

    if grid_type == "hearing_aid":
        is_previewing = True
    else:
        is_previewing_white = True

    while is_previewing or is_previewing_white:
        ret, frame = cap.read()
        if not ret: break
        with open(json_path, "r") as f:
            data = json.load(f)

        for c in data.get("contours", []):
            rect = c["bounding_rect"]
            frame = draw_HEARING_AID_grid(frame, rect) if grid_type == "hearing_aid" else draw_white_grid(frame, rect)

        cv2.imshow(f"Preview - {grid_type}", cv2.resize(frame, (display_width, display_height)))
        if cv2.waitKey(1) & 0xFF == ord('q'): break

    is_previewing = is_previewing_white = False
    cap.release()
    cv2.destroyAllWindows()


# ===================== GUI å¯åŠ¨ =====================

def create_gui():
    root = tk.Tk()
    root.title("åŸå§‹ç”»é¢æ£€æµ‹ç³»ç»Ÿ (æ— ç•¸å˜æ ¡æ­£)")
    root.geometry("600x300")

    ttk.Label(root, text="ğŸ’¡ å½“å‰æ¨¡å¼ï¼šåŸå§‹ 1920x1080 ç”»é¢ç›´å‡º", font=("å¾®è½¯é›…é»‘", 12)).pack(pady=20)

    btn_frame = ttk.Frame(root)
    btn_frame.pack(pady=10)

    ttk.Button(btn_frame, text="å¼€å§‹æ£€æµ‹ (ç²‰è‰²)",
               command=lambda: threading.Thread(target=detect_contours_by_ratio, args=((31.0, 32.0),),
                                                daemon=True).start()).grid(row=0, column=0, padx=10)
    ttk.Button(btn_frame, text="é¢„è§ˆç²‰è‰²",
               command=lambda: threading.Thread(target=preview_saved_contours, args=("hearing_aid",),
                                                daemon=True).start()).grid(row=0, column=1, padx=10)
    ttk.Button(btn_frame, text="é¢„è§ˆç™½è‰²",
               command=lambda: threading.Thread(target=preview_saved_contours, args=("white",),
                                                daemon=True).start()).grid(row=0, column=2, padx=10)

    root.mainloop()


if __name__ == "__main__":
    create_gui()